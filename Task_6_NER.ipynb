{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arseniy-Polyakov/applied_linguistics_course/blob/main/Task_6_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf-peZWxdQMc"
      },
      "source": [
        "Устанавливаем библиотеку Natasha для извлечения именованных сущностей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hscQOGYJX-IA",
        "outputId": "14acdf31-e10a-4a3f-9cad-f3c5dcec6ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natasha in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting json_repair\n",
            "  Downloading json_repair-0.47.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: slovnet>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.6.0)\n",
            "Requirement already satisfied: yargy>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.16.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.11/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from navec>=0.9.0->natasha) (2.0.2)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Downloading json_repair-0.47.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: json_repair\n",
            "Successfully installed json_repair-0.47.1\n"
          ]
        }
      ],
      "source": [
        "!pip install natasha json_repair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB6_HumEdYOz"
      },
      "source": [
        "Подключаем модули, необходимые для предобработки текста, а также извлечения и нормализации именованных сущностей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6L6mMD7NYV0S"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import folium\n",
        "import pandas as pd\n",
        "import json_repair\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import InferenceClient\n",
        "from natasha import Segmenter, Doc, NewsNERTagger, NewsEmbedding, NewsMorphTagger, NewsSyntaxParser, MorphVocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qa4LjPfdhn2"
      },
      "source": [
        "Загружаем корпус советских песен"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "niYb6QpEYfYY",
        "outputId": "6bfcdd00-500d-49b3-dd0e-b0b7328f6770"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1573"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_excel(\"corpus.xlsx\")\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAtaUk_HgD_d"
      },
      "source": [
        "Определим количество униклаьных меток, по которым будем выбирать подкорпус"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4zWnn8OgDzJ",
        "outputId": "4a2690cf-5b30-4de8-b63f-510b4d0e711b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'вера',\n",
              " 'война',\n",
              " 'герои',\n",
              " 'город',\n",
              " 'грусть',\n",
              " 'детство',\n",
              " 'дом',\n",
              " 'другое',\n",
              " 'дружба',\n",
              " 'жизнь',\n",
              " 'космос',\n",
              " 'любовь',\n",
              " 'люди',\n",
              " 'мама',\n",
              " 'мать',\n",
              " 'надежда',\n",
              " 'одиночество',\n",
              " 'память',\n",
              " 'победа',\n",
              " 'подвиг',\n",
              " 'природа',\n",
              " 'путешествие',\n",
              " 'радость',\n",
              " 'разлука',\n",
              " 'революция',\n",
              " 'религия',\n",
              " 'родина',\n",
              " 'родины',\n",
              " 'свобода',\n",
              " 'сказка',\n",
              " 'смерть',\n",
              " 'спорт',\n",
              " 'судьба',\n",
              " 'творчество',\n",
              " 'труд'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tags = [re.split(r\", |\\n\", tag) for tag in list(df[\"Tag\"])]\n",
        "tags_unique = set([re.sub(r\"[, ]\", \"\", word) for tag in tags for word in tag if word])\n",
        "tags_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suxKPT7YgSLa"
      },
      "source": [
        "В качестве исследования сформируем следующую гипотезу: в рамках тегов \"война\", \"герои\", \"память\", \"победа\", \"подвиг\" (военный кластер) будут чаще встречаться города-герои, города воинской славы и трудовой доблести; для кластера \"дом\" с тегами \"детство\", \"дом\", \"мать\", \"мама\", \"родина\" будут больше характерны топонимы деревень, сел; топонимы, не относящиеся к центральной части России (СССР)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a90oOOhkhfPa"
      },
      "source": [
        "Сделаем на основе двух выделенных кластеров два подкорпуса: \"война\" и \"дом\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "Epja1ehihnpG"
      },
      "outputs": [],
      "source": [
        "corpus = df[\"lyrics_text\"]\n",
        "tags = df[\"Tag\"]\n",
        "lyrics_tags = {}\n",
        "for i in range(len(corpus)):\n",
        "  lyrics_tags[tags[i]] = corpus[i]\n",
        "war_tags = [\"война\", \"герои\", \"память\", \"победа\", \"подвиг\"]\n",
        "home_tags = [\"детство\", \"дом\", \"мать\", \"мама\", \"родина\"]\n",
        "war_corpus = []\n",
        "home_corpus = []\n",
        "for tag in war_tags:\n",
        "  for song in list(lyrics_tags.keys()):\n",
        "    if tag in song:\n",
        "      war_corpus.append(lyrics_tags[song])\n",
        "for tag in home_tags:\n",
        "  for song in list(lyrics_tags.keys()):\n",
        "    if tag in song:\n",
        "      home_corpus.append(lyrics_tags[song])\n",
        "\n",
        "war_corpus_preprocessed = re.sub(r\"\\n\", \" \", \" \".join(war_corpus))\n",
        "home_corpus_preprocessed = re.sub(r\"\\n\", \" \", \" \".join(home_corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OoPrFXBdlz3"
      },
      "source": [
        "Определяем необходимые зависимости для задач NER и нормализации (сегментацию для NER; сегментацию, частеречную разметку и синтаксический парсинг для нормализации именованных сущностей)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_6RpLr_sY2Ey"
      },
      "outputs": [],
      "source": [
        "segmenter_war = Segmenter()\n",
        "emb_war = NewsEmbedding()\n",
        "morph_vocab_war = MorphVocab()\n",
        "ner_tagger_war = NewsNERTagger(emb_war)\n",
        "morph_tagger_war = NewsMorphTagger(emb_war)\n",
        "syntax_parser_war = NewsSyntaxParser(emb_war)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FeNjuNop-1s"
      },
      "source": [
        "Произведем извлечение именованных сущностей для военного кластера (с учетом нормализации)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0UU5Hbj_nt59"
      },
      "outputs": [],
      "source": [
        "doc = Doc(war_corpus_preprocessed)\n",
        "doc.segment(segmenter_war)\n",
        "doc.tag_morph(morph_tagger_war)\n",
        "doc.parse_syntax(syntax_parser_war)\n",
        "doc.tag_ner(ner_tagger_war)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YioQJz7GqFLs"
      },
      "source": [
        "Найдем частотное распределение топонимов, связанных тегами с военным кластером. В финальную выборку определим только те тономимы, частотность встречаемости которых больше 10 (для более наглядной визуализации)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et0TrcY5m0UN",
        "outputId": "7a0e62a4-d8d7-407f-fa8e-7075a8a18853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Россия': 85,\n",
              " 'Москва': 78,\n",
              " 'Земля': 63,\n",
              " 'Гренада': 32,\n",
              " 'Варшава': 28,\n",
              " 'Берлин': 20,\n",
              " 'Вспомним': 20,\n",
              " 'Париж': 18,\n",
              " 'Питерская': 18,\n",
              " 'Русь': 17,\n",
              " 'Сидящие': 15,\n",
              " 'Волга': 14,\n",
              " 'Нева': 14,\n",
              " 'Питерская Пронесся': 14,\n",
              " 'Грохот': 12,\n",
              " 'Афганистан': 11,\n",
              " 'Фламенго': 11,\n",
              " 'Марьина роща': 11,\n",
              " 'Садовая': 10,\n",
              " 'Скамеечка кленовая': 10,\n",
              " 'Ростов-город': 10,\n",
              " 'Болгария': 10,\n",
              " 'Херсон': 10,\n",
              " 'Манжерок': 10,\n",
              " 'Нарвой': 9,\n",
              " 'Одесса': 8,\n",
              " 'Кронштадт': 8,\n",
              " 'Бухенвальд': 8,\n",
              " 'Дон': 8,\n",
              " 'Украина': 7,\n",
              " 'Севастополь': 7,\n",
              " 'Родина': 7,\n",
              " 'Ленинград': 7,\n",
              " 'О': 7,\n",
              " 'Крым': 7,\n",
              " 'Черное море': 7,\n",
              " 'Курск': 6,\n",
              " 'Братск': 6,\n",
              " 'Калуга': 6,\n",
              " 'Иртыш': 6,\n",
              " 'Звенигород': 6,\n",
              " 'Ходившие': 5,\n",
              " 'Брест': 5,\n",
              " 'Орел': 5,\n",
              " 'Красная площадь': 5,\n",
              " 'Гремящий': 5,\n",
              " 'Урал': 5,\n",
              " 'Бреста': 5,\n",
              " 'Невский': 5,\n",
              " 'Финский залив': 5,\n",
              " 'Солнце': 5,\n",
              " 'Смоленская дорога': 5,\n",
              " 'Америка': 5,\n",
              " 'Ростов': 4,\n",
              " 'Запад': 4,\n",
              " 'Смоленск': 4,\n",
              " 'Тула': 4,\n",
              " 'Восток': 4,\n",
              " 'Брянская улица': 4,\n",
              " 'Минская улица': 4,\n",
              " 'Минск': 4,\n",
              " 'Брестская улица': 4,\n",
              " 'Люблинская улица': 4,\n",
              " 'Варшавская улица': 4,\n",
              " 'Россиею': 4,\n",
              " 'Лежащий земля': 4,\n",
              " 'Карпаты': 4,\n",
              " 'Познань': 4,\n",
              " 'Монте-Кассино': 4,\n",
              " 'Заросшим бурьяном': 4,\n",
              " 'Арбат': 4,\n",
              " 'Сегодня': 4,\n",
              " 'Кабул': 4,\n",
              " 'Дипломаты': 4,\n",
              " 'Синие замерзшими': 4,\n",
              " 'Афгани': 4,\n",
              " 'Питерская Несется': 4,\n",
              " 'Тихий Дон': 4,\n",
              " 'У': 4,\n",
              " 'Горное': 4,\n",
              " 'Под солнце': 4,\n",
              " 'Звенигород идущие': 4,\n",
              " 'Германия': 3,\n",
              " 'Первыми': 3,\n",
              " 'Комсомол': 3,\n",
              " 'Александровск': 3,\n",
              " 'И': 3,\n",
              " 'Харьков': 3,\n",
              " 'Гренадская волость': 3,\n",
              " 'Испания': 3,\n",
              " 'Гренаде Крестьяне': 3,\n",
              " 'Кремль': 3,\n",
              " 'Сквозь': 3,\n",
              " 'Дашенька': 3,\n",
              " 'Острогрудые челны': 3,\n",
              " 'Курская дуга': 3,\n",
              " 'Над город': 3,\n",
              " 'Защищя отчий край': 3,\n",
              " 'Поверженный Берлин': 3,\n",
              " 'Кенигсберг Били-били-били-били': 3,\n",
              " 'Дон-Кихоты': 3,\n",
              " 'Польша': 3,\n",
              " 'Синявино': 3,\n",
              " 'Бившийся': 3,\n",
              " 'Ладога': 3,\n",
              " 'Волхов': 3,\n",
              " 'Широкое Черное море': 3,\n",
              " 'Днепр': 3,\n",
              " 'Под Нарвой': 3,\n",
              " 'Землею': 3,\n",
              " 'От Семен Михайлович': 3,\n",
              " 'Хиросиме': 3,\n",
              " 'Освенцим': 3,\n",
              " 'Плывут': 3,\n",
              " 'Забайкалья': 3,\n",
              " 'Байкал': 3,\n",
              " 'Солнечный луч': 3,\n",
              " 'Невская': 3,\n",
              " 'Царь-колокол': 3,\n",
              " 'Развесельтесь': 3,\n",
              " 'Марьина': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "war_locations_normalized = [span.normalize(morph_vocab_war) for span in doc.spans]\n",
        "war_locations_normalized = [span.normal for span in doc.spans if span.type == \"LOC\"]\n",
        "war_locations_dict = {}\n",
        "for location in war_locations_normalized:\n",
        "  if location not in war_locations_dict:\n",
        "    war_locations_dict[location] = 1\n",
        "  else:\n",
        "    war_locations_dict[location] += 1\n",
        "for location in list(war_locations_dict.items()):\n",
        "  if war_locations_dict[location[0]] < 3:\n",
        "    del war_locations_dict[location[0]]\n",
        "war_locations_dict = dict(sorted(war_locations_dict.items(), key = lambda x:x[1], reverse=True))\n",
        "war_locations_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGc6f23hqvrQ"
      },
      "source": [
        "Произведем извлечение именнованных сущностей для кластера \"дом\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4WWf8IBx3zXE"
      },
      "outputs": [],
      "source": [
        "segmenter_home = Segmenter()\n",
        "emb_home = NewsEmbedding()\n",
        "morph_vocab_home = MorphVocab()\n",
        "ner_tagger_home = NewsNERTagger(emb_home)\n",
        "morph_tagger_home = NewsMorphTagger(emb_home)\n",
        "syntax_parser_home = NewsSyntaxParser(emb_home)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wmCOBs6yq5mw"
      },
      "outputs": [],
      "source": [
        "doc = Doc(home_corpus_preprocessed)\n",
        "doc.segment(segmenter_home)\n",
        "doc.tag_morph(morph_tagger_home)\n",
        "doc.parse_syntax(syntax_parser_home)\n",
        "doc.tag_ner(ner_tagger_home)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s43MYyhWqmkd"
      },
      "source": [
        "Найдем частотное распределение топонимов, связанных тегами с кластером дома. В финальную выборку определим только те тономимы, частотность встречаемости которых больше 4 (для более наглядной визуализации)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mHWIpUaq3Z6",
        "outputId": "eb0591b8-7e72-4fa7-98ac-58c10a164357"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Россия': 64,\n",
              " 'Москва': 41,\n",
              " 'Земля': 37,\n",
              " 'Волга': 12,\n",
              " 'Гренада': 12,\n",
              " 'Нева': 11,\n",
              " 'Марьина роща': 11,\n",
              " 'Советский Союз': 10,\n",
              " 'Одесса': 9,\n",
              " 'Америка': 9,\n",
              " 'Горький': 8,\n",
              " 'Кремль': 7,\n",
              " 'Африка': 6,\n",
              " 'Солнечный луч': 6,\n",
              " 'Сибирь': 5,\n",
              " 'Париж': 5,\n",
              " 'Арбат': 4,\n",
              " 'Свердлов': 4,\n",
              " 'За Охотный ряд': 4,\n",
              " 'На Земля': 4,\n",
              " 'Баку': 4,\n",
              " 'Берлин': 4,\n",
              " 'Подмосковная': 4,\n",
              " 'Горное': 4,\n",
              " 'Керчь': 4,\n",
              " 'Русь': 4,\n",
              " 'Аляска': 4,\n",
              " 'Бухенвальд': 4,\n",
              " 'Камчатка О-о': 4,\n",
              " 'Украина': 3,\n",
              " 'Ростов': 3,\n",
              " 'Иран': 3,\n",
              " 'Ленинград': 3,\n",
              " 'Кронштадт': 3,\n",
              " 'Пекин': 3,\n",
              " 'Нам': 3,\n",
              " 'Братск': 3,\n",
              " 'Тусе': 3,\n",
              " 'О': 3,\n",
              " 'Металлурги': 3,\n",
              " 'Испания': 3,\n",
              " 'Степь': 3,\n",
              " 'Ленинские горы': 3,\n",
              " 'Калуга': 3,\n",
              " 'Марьина': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "home_locations_normalized = [span.normalize(morph_vocab_home) for span in doc.spans]\n",
        "home_locations_normalized = [span.normal for span in doc.spans if span.type == \"LOC\"]\n",
        "home_locations_dict = {}\n",
        "for location in home_locations_normalized:\n",
        "  if location not in home_locations_dict:\n",
        "    home_locations_dict[location] = 1\n",
        "  else:\n",
        "    home_locations_dict[location] += 1\n",
        "for location in list(home_locations_dict.items()):\n",
        "  if home_locations_dict[location[0]] < 3:\n",
        "    del home_locations_dict[location[0]]\n",
        "home_locations_dict = dict(sorted(home_locations_dict.items(), key = lambda x:x[1], reverse=True))\n",
        "home_locations_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INwzcDR-2uXQ"
      },
      "source": [
        "Визуализируем самые часто встречающиеся города среди кластера \"война\" на карте. Координаты были найдены на [сайте](https://time-in.ru/coordinates), однако потенциально поиск координат может быть автоматизирован с помощью API Яндекс Карт (является платным источником)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2W-EE6UUrsZI"
      },
      "outputs": [],
      "source": [
        "war_cities = pd.DataFrame({\"city\": [\"Москва\", \"Одесса\", \"Горький\", \"Париж\", \"Баку\", \"Берлин\", \"Керчь\", \"Ростов\",\n",
        "                                    \"Ленинград\", \"Кронштадт\", \"Пекин\", \"Братск\", \"Калуга\"],\n",
        "                          \"frequency\": [41, 9, 8, 5, 4, 4, 4, 3, 3, 3, 3, 3, 3]})\n",
        "\n",
        "coordinates = {\"Москва\": (55.7558, 37.6176),\n",
        "               \"Одесса\": (46.4775, 30.7326),\n",
        "               \"Горький\": (56.3287, 44.002),\n",
        "               \"Париж\": (48.8534, 2.3488),\n",
        "               \"Баку\": (40.3777, 49.892),\n",
        "               \"Берлин\": (52.5244, 13.4105),\n",
        "               \"Керчь\": (45.3531, 36.4743),\n",
        "               \"Ростов\": (47.2313, 39.7233),\n",
        "               \"Ленинград\": (59.9386, 30.3141),\n",
        "               \"Кронштадт\": (59.5943, 29.4600),\n",
        "               \"Пекин\": (39.9075, 116.397),\n",
        "               \"Братск\": (39.9075, 116.397),\n",
        "               \"Калуга\": (54.5293, 36.2754)}\n",
        "\n",
        "map = folium.Map(location=[55.7558, 37.6176], zoom_start=4)\n",
        "\n",
        "for index, row in war_cities.iterrows():\n",
        "    city = row['city']\n",
        "    frequency = row['frequency']\n",
        "    lat, lon = coordinates[city]\n",
        "    folium.CircleMarker([lat, lon], radius=frequency/10, popup=city).add_to(map)\n",
        "\n",
        "map.save(\"war_cities.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nayQn9ye22Up"
      },
      "source": [
        "Визуализируем самые часто встречающиеся города среди кластера \"дом\" на карте\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FqrEvF2Y28At"
      },
      "outputs": [],
      "source": [
        "home_cities = pd.DataFrame({\"city\": [\"Москва\", \"Одесса\", \"Горький\", \"Париж\", \"Баку\", \"Берлин\", \"Керчь\", \"Ростов\",\n",
        "                                    \"Ленинград\", \"Кронштадт\", \"Пекин\", \"Братск\", \"Калуга\"],\n",
        "                          \"frequency\": [41, 9, 8, 5, 4, 4, 4, 3, 3, 3, 3, 3, 3]})\n",
        "\n",
        "coordinates = {\"Москва\": (55.7558, 37.6176),\n",
        "               \"Одесса\": (46.4775, 30.7326),\n",
        "               \"Горький\": (56.3287, 44.002),\n",
        "               \"Париж\": (48.8534, 2.3488),\n",
        "               \"Баку\": (40.3777, 49.892),\n",
        "               \"Берлин\": (52.5244, 13.4105),\n",
        "               \"Керчь\": (45.3531, 36.4743),\n",
        "               \"Ростов\": (47.2313, 39.7233),\n",
        "               \"Ленинград\": (59.9386, 30.3141),\n",
        "               \"Кронштадт\": (59.5943, 29.4600),\n",
        "               \"Пекин\": (39.9075, 116.397),\n",
        "               \"Братск\": (39.9075, 116.397),\n",
        "               \"Калуга\": (54.5293, 36.2754)}\n",
        "\n",
        "map = folium.Map(location=[55.7558, 37.6176], zoom_start=4)\n",
        "\n",
        "for index, row in home_cities.iterrows():\n",
        "    city = row['city']\n",
        "    frequency = row['frequency']\n",
        "    lat, lon = coordinates[city]\n",
        "    folium.CircleMarker([lat, lon], radius=frequency/10, popup=city).add_to(map)\n",
        "\n",
        "map.save(\"home_cities.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6712a2sz5u8r"
      },
      "source": [
        "Вывод: гипотеза касаемо военного кластера частично подтвердилась, действительно в песнях часто упомянаются города-герои, а также города, в которых происходили ожесточенные бои (преимущественно в период Великой Отечественной войны), а именно города: Москва, Одесса, Нижний Новгород (Горький), Керчь и другие.\n",
        "\n",
        "Однако некоторые города, в которых не было боев в период Великой Отечественной войны также попали в данную выборку, а именно города Пекин, Братск. Есть гипотеза (не изучая лирику), что Братск в песнях упоминается в значении трудового города, города стройки Байкало-Амурской магистрали, поэтому воспевается как город героев, труженников-железнодорожников, как подвиг народов СССР. Насчет Пекина есть гипотеза о том, что он воспевается как город, в котором были сражения в контексте Второй мировой войны, сражения против Японии.\n",
        "\n",
        "\n",
        "Также в результате анализа было выяснено, что два кластера \"война\" и \"дом\" являются взаимозаменяющими на данном датасете, результаты по частотным городам совпадают (общее количество сущностей разное, как и частотность употребления сущностей, не связанных с наименованием городов), поэтому в данном случае заявленную ранее гипотезу нельзя ни доказать, ни опровергнуть\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведем сравнение библиотеки natasha с большими языковыми моделями (meta-llama/Llama-4-Scout-17B-16E-Instruct) для извлечения именнованных сущностей локаций (тэг LOC) для кластеров \"война\" и \"дом\""
      ],
      "metadata": {
        "id": "zpcucaEpp4w9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним подключение к модели meta-llama/Llama-4-Scout-17B-16E-Instruct провайдера novita с помощью Hugging Face API"
      ],
      "metadata": {
        "id": "aoiNE3IA2T4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "KQ9DZUVhXD4D"
      },
      "outputs": [],
      "source": [
        "def llm_ner(model: str, provider: str, text: str) -> str:\n",
        "  client = InferenceClient(\n",
        "    provider=provider,\n",
        "    api_key=userdata.get(\"API_KEY\")\n",
        "  )\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"\"\"You are an expert in finding Named Entities in the text.\n",
        "            Your goal is to find all location names (all geographical objets: countries, cities, regions)\n",
        "            in the text {text} and count how many times they used in the text.\n",
        "            You must provide an answer in a JSON format. Sort the final JSON from the top to the bottom.\n",
        "            For example:\n",
        "            'Москва': 15,\n",
        "            'Санкт-Петербург': 10,\n",
        "            'Казань': 8,\n",
        "            'Нижний Новгород': 5,\n",
        "            'Пермь': 3\n",
        "            You must strictly provide an answer only in Russian. Do not add any additional information just provide a JSON sctructure.\n",
        "            Do not add any additional cities which you know, just add locations which you found in the text\n",
        "            \"\"\"\n",
        "        }\n",
        "    ],\n",
        "  )\n",
        "  return completion.choices[0].message"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем ответ модели и преобразуем к json формату"
      ],
      "metadata": {
        "id": "rwWboVl92aIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
        "provider = \"novita\"\n",
        "llm_answer_war = llm_ner(model, provider, war_corpus_preprocessed).content\n",
        "llm_answer_war_json = json_repair.loads(llm_answer_war)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Rr1rYhYasBiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Многие большие языковые модели плохо справляются с подсчетом количественных метрик, велик риск галлюцинаций. В связи с этим более релевантной выглядит задача извлечения сущностей без подсчета частоты их встречаемости в тексте."
      ],
      "metadata": {
        "id": "iCFVUPBhxGuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем количество топонимов, которые встретились среди выборки, сделанной с помощью natasha, срели выборки, сделанной с помощью модели meta-llama/Llama-4-Scout-17B-16E-Instruct. Найдем общие топонимы"
      ],
      "metadata": {
        "id": "plIAwXkc2hLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llama_entities_war = [re.sub(r\"[^А-Яа-яёЁ\\s]\", \"\", item) for item in list(llm_answer_war_json.keys())]\n",
        "natasha_entities_war = list(war_locations_dict.keys())\n",
        "count_same = len([item for item in llama_entities_war if item in natasha_entities_war])\n",
        "print(f\"Количество топонимов, которые встретились и в выборке llama и в выборке natasha {count_same}\")\n",
        "print(f\"Общее количество топонимов, которые есть в выборке natasha {len(natasha_entities_war)}\")\n",
        "print(f\"Общее количество топонимов, которые есть в выборке llama {len(llama_entities_war)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JbPJ_Cl1vimF",
        "outputId": "b9ce5dca-72e1-458f-87a9-e32e2b56879d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество топонимов, которые встретились и в выборке llama и в выборке natasha 39\n",
            "Общее количество топонимов, которые есть в выборке natasha 121\n",
            "Общее количество топонимов, которые есть в выборке llama 117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод: большая языковая модель meta-llama/Llama-4-Scout-17B-16E-Instruct не лучшим образом справляется с извлечением именованных сущностей на данных корпуса советской песни. В данном конкретном кейсе стоит использовать библиотеку natasha, которая даст большую точность"
      ],
      "metadata": {
        "id": "nbqXK76U7aHN"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy4WhQsQVq7TK0tAE7kkBN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}